{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHLT Final Project: Semantinc Textual Similarity\n",
    "Jordi Armengol - Joan LLop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "We start by downloading the SemEval 2012 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-06 13:39:06--  https://gebakx.github.io/ihlt/sts/resources/train.tgz\n",
      "Resolving gebakx.github.io (gebakx.github.io)... 185.199.111.153, 185.199.110.153, 185.199.109.153, ...\n",
      "Connecting to gebakx.github.io (gebakx.github.io)|185.199.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 125822 (123K) [application/octet-stream]\n",
      "Saving to: ‘data/train.tgz.4’\n",
      "\n",
      "train.tgz.4         100%[===================>] 122,87K  --.-KB/s    in 0,04s   \n",
      "\n",
      "2019-12-06 13:39:06 (2,91 MB/s) - ‘data/train.tgz.4’ saved [125822/125822]\n",
      "\n",
      "--2019-12-06 13:39:06--  https://gebakx.github.io/ihlt/sts/resources/test-gold.tgz\n",
      "Resolving gebakx.github.io (gebakx.github.io)... 185.199.111.153, 185.199.110.153, 185.199.109.153, ...\n",
      "Connecting to gebakx.github.io (gebakx.github.io)|185.199.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118094 (115K) [application/octet-stream]\n",
      "Saving to: ‘data/test-gold.tgz.4’\n",
      "\n",
      "test-gold.tgz.4     100%[===================>] 115,33K  --.-KB/s    in 0,04s   \n",
      "\n",
      "2019-12-06 13:39:07 (2,66 MB/s) - ‘data/test-gold.tgz.4’ saved [118094/118094]\n",
      "\n",
      "/home/nhikia/Documents/AI/IHLT/IHLT-MAI/lab/project/data\n",
      "train/\n",
      "train/00-readme.txt\n",
      "train/STS.output.MSRpar.txt\n",
      "train/STS.input.SMTeuroparl.txt\n",
      "train/STS.input.MSRpar.txt\n",
      "train/STS.gs.MSRpar.txt\n",
      "train/STS.input.MSRvid.txt\n",
      "train/STS.gs.MSRvid.txt\n",
      "train/correlation.pl\n",
      "train/STS.gs.SMTeuroparl.txt\n",
      "test-gold/\n",
      "test-gold/STS.input.MSRpar.txt\n",
      "test-gold/STS.gs.MSRpar.txt\n",
      "test-gold/STS.input.MSRvid.txt\n",
      "test-gold/STS.gs.MSRvid.txt\n",
      "test-gold/STS.input.SMTeuroparl.txt\n",
      "test-gold/STS.gs.SMTeuroparl.txt\n",
      "test-gold/STS.input.surprise.SMTnews.txt\n",
      "test-gold/STS.gs.surprise.SMTnews.txt\n",
      "test-gold/STS.input.surprise.OnWN.txt\n",
      "test-gold/STS.gs.surprise.OnWN.txt\n",
      "test-gold/STS.gs.ALL.txt\n",
      "test-gold/00-readme.txt\n",
      "/home/nhikia/Documents/AI/IHLT/IHLT-MAI/lab/project\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!wget https://gebakx.github.io/ihlt/sts/resources/train.tgz --directory-prefix=data\n",
    "!wget https://gebakx.github.io/ihlt/sts/resources/test-gold.tgz --directory-prefix=data\n",
    "%cd data\n",
    "!tar zxvf train.tgz\n",
    "!tar zxvf test-gold.tgz\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "train_files = ['MSRpar', 'MSRvid', 'SMTeuroparl']\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for file in train_files:\n",
    "    with open(os.path.join('data', 'train', 'STS.input.' + file + '.txt'), 'r') as f:\n",
    "        train_data += [sent.split('\\t') for sent in f.readlines()]\n",
    "    with open(os.path.join('data', 'train', 'STS.gs.' + file + '.txt'), 'r') as f:\n",
    "        train_labels += [float(num) for num in f.readlines()]\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_files = ['MSRpar', 'MSRvid', 'SMTeuroparl', 'surprise.OnWN', 'surprise.SMTnews']\n",
    "test_data = []\n",
    "test_labels = []\n",
    "for file in test_files:\n",
    "    with open(os.path.join('data', 'test-gold', 'STS.input.' + file + '.txt'), 'r') as f:\n",
    "        test_data += [sent.split('\\t') for sent in f.readlines()]\n",
    "    with open(os.path.join('data', 'test-gold', 'STS.gs.'+ file + '.txt'), 'r') as f:\n",
    "        test_labels += [float(num) for num in f.readlines()]\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative 1: Linguistic feature engineering and classical machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def sent2features(sent):\n",
    "    features = []\n",
    "    features += nltk.word_tokenize(sent)\n",
    "    # ...\n",
    "    return features\n",
    "\n",
    "\n",
    "pairs_of_features = [(sent2features(sent1), sent2features(sent2)) for sent1, sent2 in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distances between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import jaccard_distance\n",
    "\n",
    "def distance(features1, features2):\n",
    "    distances = []\n",
    "    distances.append(jaccard_distance(set(features1), set(features2)))\n",
    "    # ...\n",
    "    return np.array(distances)\n",
    "\n",
    "\n",
    "distances = np.array([distance(features1, features2) for features1, features2 in pairs_of_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(distances, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import sklearn\n",
    "def evaluate(true_labels, predicted_labels):\n",
    "    pearson, p_value = stats.pearsonr(true_labels, predicted_labels)\n",
    "    return pearson, p_value\n",
    "def cross_validate(data, labels, model, n_folds=5, seed=1):\n",
    "    kf = sklearn.model_selection.KFold(n_splits=n_folds, random_state=seed)\n",
    "    average_pearson = 0\n",
    "    for train_index, val_index in kf.split(data):\n",
    "        X_train, X_val = data[train_index], data[val_index]\n",
    "        y_train, y_val = labels[train_index], labels[val_index]\n",
    "        m = model.fit(X_train, y_train)\n",
    "        predicted_labels = model.predict(X_val)\n",
    "        pearson, _ = evaluate(y_val, predicted_labels)\n",
    "        average_pearson += pearson\n",
    "    return average_pearson/n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4109743529779384"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(distances, train_labels, LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative 2: Transfer learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
