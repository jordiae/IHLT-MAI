{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from math import inf, log\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(text_lines,l=None):\n",
    "    preprocessed = []\n",
    "    for index, line in enumerate(text_lines):\n",
    "        num, sentence = line.split('\\t')\n",
    "        new_line = ''.join([c.lower() for c in sentence if not c.isdigit()])\n",
    "        new_line = ' '.join(new_line.split())\n",
    "        preprocessed.append(new_line)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "langs = ['eng', 'deu', 'fra', 'ita', 'nld', 'spa']\n",
    "dataset = {}\n",
    "for l in langs:\n",
    "    dataset[l] = {}\n",
    "    with open('langId/' + l + '_trn.txt', 'r') as file:\n",
    "        dataset[l]['trn'] = file.readlines()\n",
    "    with open('langId/' + l + '_tst.txt', 'r') as file:\n",
    "        dataset[l]['tst'] = file.readlines()\n",
    "    dataset[l]['trn'] = '  ' + '  '.join(preprocessing(dataset[l]['trn'],l)) + '  '\n",
    "    dataset[l]['tst'] = ['  ' + sentence + '  ' for sentence in preprocessing(dataset[l]['tst'],l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, clean_corpus, lang):\n",
    "        self.trigrams = TrigramCollocationFinder.from_words(clean_corpus)\n",
    "        self.trigrams.apply_freq_filter(5)\n",
    "        self.bigrams = self.trigrams.bigram_finder()\n",
    "        self.lambd = 1\n",
    "        self.V = len(self.trigrams.ngram_fd)\n",
    "        self.lang = lang\n",
    "            \n",
    "    def infer(self, trigram):\n",
    "        # N: bigram_freq, V: train trigrams vocabulary size, ci: trigram frequency\n",
    "        ci = self.trigrams.ngram_fd[trigram]\n",
    "        (t1, t2, t3) = trigram\n",
    "        N = self.bigrams.ngram_fd[(t1, t2)]\n",
    "        return (ci + self.lambd) / (N + self.lambd * self.V)\n",
    "        \n",
    "        \n",
    "    def eval(self, sentence):\n",
    "        # log probablity, not perplexity\n",
    "        p = 1\n",
    "        trigrams = TrigramCollocationFinder.from_words(sentence)\n",
    "        for trigram in trigrams.ngram_fd:\n",
    "            p += log(self.infer(trigram))\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training English ...\n",
      "Training Deutsch ...\n",
      "Training Français ...\n",
      "Training Italiano ...\n",
      "Training Nederlands ...\n",
      "Training Español ...\n",
      "Training time: 70.53643941879272\n"
     ]
    }
   ],
   "source": [
    "lt0 = time.time()\n",
    "print('Training English ...')\n",
    "engModel = LanguageModel(dataset['eng']['trn'], 'eng')\n",
    "print('Training Deutsch ...')\n",
    "deuModel = LanguageModel(dataset['deu']['trn'], 'deu')\n",
    "print('Training Français ...')\n",
    "fraModel = LanguageModel(dataset['fra']['trn'], 'fra')\n",
    "print('Training Italiano ...')\n",
    "itaModel = LanguageModel(dataset['ita']['trn'], 'ita')\n",
    "print('Training Nederlands ...')\n",
    "nldModel = LanguageModel(dataset['nld']['trn'], 'nld')\n",
    "print('Training Español ...')\n",
    "spaModel = LanguageModel(dataset['spa']['trn'], 'spa')\n",
    "lt1 = time.time()\n",
    "print('Training time:', lt1 - lt0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metamodel(models, sentence):\n",
    "    max_p = inf\n",
    "    res = None\n",
    "    for model in models:\n",
    "        p = model.eval(sentence)\n",
    "        if abs(p) < max_p:\n",
    "            # (log probablity)\n",
    "            max_p = abs(p)\n",
    "            res = model.lang\n",
    "    return res\n",
    "\n",
    "models = [engModel, deuModel, fraModel, itaModel, nldModel, spaModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on ... eng\n",
      "Evaluating on ... deu\n",
      "Evaluating on ... fra\n",
      "Evaluating on ... ita\n",
      "Evaluating on ... nld\n",
      "Evaluating on ... spa\n",
      "Inference time: 209.0808641910553\n"
     ]
    }
   ],
   "source": [
    "tt0 = time.time()\n",
    "confusion_matrix = {}\n",
    "for l in langs:\n",
    "    print('Evaluating on ...', l)\n",
    "    confusion_matrix[l] = {}\n",
    "    for sentence in dataset[l]['tst']:\n",
    "        res = metamodel(models, sentence)\n",
    "        if res in confusion_matrix[l]:\n",
    "            confusion_matrix[l][res] += 1\n",
    "        else:\n",
    "            confusion_matrix[l][res] = 1\n",
    "tt1 = time.time()\n",
    "\n",
    "print('Inference time:', tt1-tt0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***|*eng|*deu|*fra|*ita|*nld|*spa|\n",
      "eng|9985|   .|   1|   .|   1|   .|\n",
      "deu|  11|9971|   .|   1|   6|   1|\n",
      "fra|  11|   .|9980|   5|   3|   1|\n",
      "ita|   8|   .|   1|9987|   .|   4|\n",
      "nld|  28|   7|   2|   4|9957|   2|\n",
      "spa|   4|   .|   1|   3|   .|9992|\n",
      "----------------------------------\n",
      "Accuracy 0.9982493289094153\n",
      "Training time: 70.53643941879272\n",
      "Inference time: 209.0808641910553\n"
     ]
    }
   ],
   "source": [
    "def prettify(conf_mat):\n",
    "    print('***', end = '')\n",
    "    for l in langs:\n",
    "        print('|*' + l, end = '')\n",
    "    print('|')\n",
    "    for l in langs:\n",
    "        print(l, end = '|')\n",
    "        for l2 in langs:\n",
    "            if l2 in conf_mat[l]:\n",
    "                print(str(conf_mat[l][l2]).rjust(4), end = '|')\n",
    "            else:\n",
    "                print(str('   .'), end = '|')\n",
    "        print()\n",
    "    print('-'*34)\n",
    "\n",
    "def get_accuracy(conf_mat):\n",
    "    total = 0\n",
    "    right = 0\n",
    "    for l in langs:\n",
    "        right += conf_mat[l][l]\n",
    "        total += sum(conf_mat[l].values())\n",
    "    return right/total\n",
    "    \n",
    "prettify(confusion_matrix)\n",
    "print('Accuracy', get_accuracy(confusion_matrix))\n",
    "print('Training time:', lt1 - lt0)\n",
    "print('Inference time:', tt1-tt0)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
