{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 3: Sequence Level. Building a NER chunker with CRF.\n",
    "Jordi Armengol - Joan Llop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "import pycrfsuite\n",
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "from sklearn import svm, metrics\n",
    "# gensim can be downloaded using pip install -U gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'conll2003' folder with the files 'eng.train', 'eng.testa' and 'eng.testb' is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = ConllCorpusReader('conll2003', 'eng.train', ['words', 'pos', 'ne', 'chunk']).iob_sents()[1:]\n",
    "testa = ConllCorpusReader('conll2003', 'eng.testa', ['words', 'pos', 'ne', 'chunk']).iob_sents()[1:]\n",
    "# testb = ConllCorpusReader('conll2003', 'eng.testb', ['words', 'pos', 'ne', 'chunk']).iob_sents()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_from_sent(sent):\n",
    "    return [words for words, postag, label in sent]\n",
    "\n",
    "\n",
    "# used when all features are embeddings\n",
    "def get_embedded_word_features(i, words, model):\n",
    "    word_features = []\n",
    "    for j in range(len(words)):\n",
    "        word_features.append(str(model.wv.similarity(words[i], words[j])))\n",
    "    return word_features\n",
    "\n",
    "\n",
    "# used when all features are embeddings\n",
    "def get_embedded_sentence_features(sent, model):\n",
    "    words = get_words_from_sent(sent)\n",
    "    features = [get_embedded_word_features(i, words, model) for i in range(len(words))]\n",
    "    return features\n",
    "\n",
    "\n",
    "# used when all features are embeddings\n",
    "def get_embedded_features(corpus):\n",
    "    words = [get_words_from_sent(sent) for sent in corpus]\n",
    "    model = gensim.models.Word2Vec(words, min_count = 1, size = 100, window = 5)\n",
    "    return [get_embedded_sentence_features(sent, model) for sent in corpus]\n",
    "\n",
    "\n",
    "def get_word_features(i, sent):\n",
    "    words = get_words_from_sent(sent)\n",
    "    word = words[i]\n",
    "    features = []\n",
    "    features.append('word is upper: ' + str(word.isupper())) # is uppercase\n",
    "    features.append('word is digit: ' + str(word.isdigit())) # is a digit\n",
    "    features.append('Beggining of sentence: ' + str(i==0)) # beggining of a sentence\n",
    "    features.append('End of sentence: ' + str(i==len(words)-1)) # end of sentence\n",
    "    features.append('lenght of word: ' + str(len(words))) # lenght of word\n",
    "    features.append('postag: ' + str(sent[i][1])) # Postag                   \n",
    "    if (i > 0):\n",
    "        previous_word = words[i-1]\n",
    "        features.append('postag previous word: ' + str(sent[i-1][1]))\n",
    "        features.append('lenght of previous word: ' + str(len(previous_word)))\n",
    "        features.append('previous word is upper: ' + str(previous_word.isupper()))\n",
    "        features.append('previous word is digit: ' + str(previous_word.isdigit()))\n",
    "    if (i > 1):\n",
    "        previous_word = words[i-2]\n",
    "        features.append('postag second previous word: ' + str(sent[i-1][1]))\n",
    "        features.append('lenght of second previous word: ' + str(len(previous_word)))\n",
    "        features.append('second previous word is upper: ' + str(previous_word.isupper()))\n",
    "        features.append('second previous word is digit: ' + str(previous_word.isdigit()))\n",
    "    if (i < len(words)-1):\n",
    "        next_word = words[i+1]\n",
    "        features.append('postag next word: ' + str(sent[i+1][1]))\n",
    "        features.append('lenght of next word: ' + str(len(next_word)))\n",
    "        features.append('next word is upper: ' + str(next_word.isupper()))\n",
    "        features.append('next word is digit: ' + str(next_word.isdigit()))\n",
    "    if (i < len(words)-2):\n",
    "        next_word = words[i+2]\n",
    "        features.append('postag second next word: ' + str(sent[i+1][1]))\n",
    "        features.append('lenght of second next word: ' + str(len(next_word)))\n",
    "        features.append('second next word is upper: ' + str(next_word.isupper()))\n",
    "        features.append('second next word is digit: ' + str(next_word.isdigit()))\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_sentence_features(sent):\n",
    "    return [get_word_features(i, sent) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def get_features(corpus):\n",
    "    return [get_sentence_features(sent) for sent in corpus]\n",
    "    \n",
    "                        \n",
    "def get_sentence_labels(sent):\n",
    "    return [label for words, postag, label in sent]\n",
    "                        \n",
    "                        \n",
    "def get_labels(corpus):\n",
    "    return [get_sentence_labels(sent) for sent in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.38 s, sys: 284 ms, total: 5.67 s\n",
      "Wall time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train_features = get_embedded_features(train)\n",
    "train_features = get_features(train)\n",
    "train_labels = get_labels(train)\n",
    "\n",
    "# testa_features = get_embedded_features(testa)\n",
    "testa_features = get_features(testa)\n",
    "testa_labels = get_labels(testa)\n",
    "\n",
    "# testb_features = get_features(testb)\n",
    "# testb_labels = get_labels(testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.89 s, sys: 27.8 ms, total: 2.92 s\n",
      "Wall time: 2.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CRF = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for x, y in zip(train_features, train_labels):\n",
    "    CRF.append(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 120 ms, total: 1min 56s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CRF.train('conll2003-eng.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.907928040185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhikia/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-MISC       0.00      0.00      0.00         4\n",
      "       I-LOC       0.53      0.56      0.55      2094\n",
      "      I-MISC       0.35      0.14      0.20      1264\n",
      "       I-ORG       0.55      0.49      0.52      2092\n",
      "       I-PER       0.74      0.77      0.76      3149\n",
      "           O       0.96      0.98      0.97     42759\n",
      "\n",
      "    accuracy                           0.91     51362\n",
      "   macro avg       0.52      0.49      0.50     51362\n",
      "weighted avg       0.90      0.91      0.90     51362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2003-eng.train')\n",
    "y_pred = []\n",
    "\n",
    "# use testa_features for validation and testb_features for testing\n",
    "for sentence_pred in [tagger.tag(x) for x in testa_features]:\n",
    "    for pred in sentence_pred:\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "# use testa_labels for validation and testb_labels for testing\n",
    "y_test = []\n",
    "for sentence_labels in testa_labels:\n",
    "    for label in sentence_labels:\n",
    "        y_test.append(label)\n",
    "        \n",
    "# Print results \n",
    "print('accuracy =', metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
