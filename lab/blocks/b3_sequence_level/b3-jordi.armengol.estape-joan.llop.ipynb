{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 3: Sequence Level. Building a NER chunker with CRF.\n",
    "Jordi Armengol - Joan Llop\n",
    "\n",
    "In this block we want to discover the name entities of sentences using conditional random fields. \n",
    "#### CRFs \n",
    "Usually a neural network is model that takes a single input and returns the most likely label, but with conditional random fields, the previous inputs and the next inputs matter in the task of assigning a label to an instance. Therefore, we can think of them as a way of modeling the join distribution of a whole sequence of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "import pycrfsuite\n",
    "# gensim can be downloaded using pip install -U gensim\n",
    "import gensim # m'ha semblat inutil, crec que ho hauriem de borrar de cara a l'entrega\n",
    "from gensim.models import Word2Vec # \" \"\n",
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "We will use the english files of the conll2003 corpus. A 'conll2003' folder with the files 'eng.train', 'eng.testa' and 'eng.testb' is required to be in the same folder as the notebook.\n",
    "\n",
    "The data will be a list of sentences of tripplets: (word, pos, ne). we will use the testa for validation purposes and the testb as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = ConllCorpusReader('conll2003', 'eng.train', ['words', 'pos', 'ne', 'chunk']).iob_sents()[1:]\n",
    "testa = ConllCorpusReader('conll2003', 'eng.testa', ['words', 'pos', 'ne', 'chunk']).iob_sents()[1:]\n",
    "testb = ConllCorpusReader('conll2003', 'eng.testb', ['words', 'pos', 'ne', 'chunk']).iob_sents()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "#### The features\n",
    "In order to train our CRF we need to create the features (from the data we have the words and the pos). We have decided to use the following features:\n",
    "- The word in lowercase\n",
    "- The POS\n",
    "- The lenght of the word\n",
    "- A bool that indicates if the word is the beginning of the sentence\n",
    "- A bool that indicates if the word is the end of the sentence\n",
    "- A bool that indicates if the word is all in uppercase\n",
    "- A bool that indicates if the word is a digit\n",
    "- A bool that indicates if the word is a title\n",
    "\n",
    "We repeat all these features for the two previous words and for the two next words of the sentence (if they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_sent(sent):\n",
    "    return [words for words, postag, label in sent]\n",
    "\n",
    "\n",
    "# used when all features are embeddings\n",
    "def get_embedded_word_features(i, words, model):\n",
    "    word_features = []\n",
    "    for j in range(len(words)):\n",
    "        word_features.append(str(model.wv.similarity(words[i], words[j])))\n",
    "    return word_features\n",
    "\n",
    "\n",
    "# used when all features are embeddings\n",
    "def get_embedded_sentence_features(sent, model):\n",
    "    words = get_words_from_sent(sent)\n",
    "    features = [get_embedded_word_features(i, words, model) for i in range(len(words))]\n",
    "    return features\n",
    "\n",
    "\n",
    "# used when all features are embeddings\n",
    "def get_embedded_features(corpus):\n",
    "    words = [get_words_from_sent(sent) for sent in corpus]\n",
    "    model = gensim.models.Word2Vec(words, min_count = 1, size = 100, window = 5)\n",
    "    return [get_embedded_sentence_features(sent, model) for sent in corpus]\n",
    "\n",
    "\n",
    "def get_word_features(i, sent):\n",
    "    words = get_words_from_sent(sent)\n",
    "    word = words[i]\n",
    "    features = []\n",
    "    features.append('lowercase word: ' + word.lower()) # word in lowercase\n",
    "    features.append('postag: ' + str(sent[i][1])) # Postag                   \n",
    "    features.append('lenght of word: ' + str(len(words))) # lenght of word\n",
    "    features.append('BOS: ' + str(i==0)) # beggining of a sentence\n",
    "    features.append('EOF: ' + str(i==len(words)-1)) # end of sentence\n",
    "    features.append('word is upper: ' + str(word.isupper())) # is uppercase\n",
    "    features.append('word is digit: ' + str(word.isdigit())) # is a digit\n",
    "    features.append('word is title: ' + str(word.istitle())) # is a title\n",
    "    if (i > 0):\n",
    "        previous_word = words[i-1]\n",
    "        features.append('lowercase previous word: ' + previous_word.lower())\n",
    "        features.append('postag previous word: ' + str(sent[i-1][1]))\n",
    "        features.append('lenght of previous word: ' + str(len(previous_word)))\n",
    "        features.append('previous word is BOS: ' + str(i-1==0))\n",
    "        features.append('previous word is EOF: ' + str(i-1==len(words)-1))\n",
    "        features.append('previous word is upper: ' + str(previous_word.isupper()))\n",
    "        features.append('previous word is digit: ' + str(previous_word.isdigit()))\n",
    "        features.append('previous word is title: ' + str(previous_word.istitle()))\n",
    "    if (i > 1):\n",
    "        previous_word = words[i-2]\n",
    "        features.append('lowercase second previous word: ' + previous_word.lower())\n",
    "        features.append('postag second previous word: ' + str(sent[i-2][1]))\n",
    "        features.append('lenght of second previous word: ' + str(len(previous_word)))\n",
    "        features.append('second previous word is BOS: ' + str(i-2==0))\n",
    "        features.append('second previous word is EOF: ' + str(i-2==len(words)-1))\n",
    "        features.append('second previous word is upper: ' + str(previous_word.isupper()))\n",
    "        features.append('second previous word is digit: ' + str(previous_word.isdigit()))\n",
    "        features.append('second previous word is title: ' + str(previous_word.istitle()))\n",
    "    if (i < len(words)-1):\n",
    "        next_word = words[i+1]\n",
    "        features.append('lowercase next word: ' + next_word.lower())\n",
    "        features.append('postag next word: ' + str(sent[i+1][1]))\n",
    "        features.append('lenght of next word: ' + str(len(next_word)))\n",
    "        features.append('next word is BOS: ' + str(i+1==0))\n",
    "        features.append('next word is EOF: ' + str(i+1==len(words)-1))\n",
    "        features.append('next word is upper: ' + str(next_word.isupper()))\n",
    "        features.append('next word is digit: ' + str(next_word.isdigit()))\n",
    "        features.append('next word is title: ' + str(next_word.istitle()))\n",
    "    if (i < len(words)-2):\n",
    "        next_word = words[i+2]\n",
    "        features.append('lowercase second next word: ' + next_word.lower())\n",
    "        features.append('postag second next word: ' + str(sent[i+2][1]))\n",
    "        features.append('lenght of second next word: ' + str(len(next_word)))\n",
    "        features.append('second next word is BOS: ' + str(i+2==0))\n",
    "        features.append('second next word is EOF: ' + str(i+2==len(words)-1))\n",
    "        features.append('second next word is upper: ' + str(next_word.isupper()))\n",
    "        features.append('second next word is digit: ' + str(next_word.isdigit()))\n",
    "        features.append('second next word is title: ' + str(next_word.istitle()))\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_sentence_features(sent):\n",
    "    return [get_word_features(i, sent) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def get_features(corpus):\n",
    "    return [get_sentence_features(sent) for sent in corpus]\n",
    "    \n",
    "                        \n",
    "def get_sentence_labels(sent):\n",
    "    return [label for words, postag, label in sent]\n",
    "                        \n",
    "                        \n",
    "def get_labels(corpus):\n",
    "    return [get_sentence_labels(sent) for sent in corpus]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train phase\n",
    "We separate the data in features and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.07 s, sys: 500 ms, total: 9.57 s\n",
      "Wall time: 9.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train_features = get_embedded_features(train)\n",
    "\n",
    "train_features = get_features(train)\n",
    "train_labels = get_labels(train)\n",
    "\n",
    "# testa_features = get_embedded_features(testa)\n",
    "\n",
    "testa_features = get_features(testa)\n",
    "testa_labels = get_labels(testa)\n",
    "\n",
    "# testb_features = get_embedded_features(testb)\n",
    "\n",
    "testb_features = get_features(testb)\n",
    "testb_labels = get_labels(testb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add all sentences (where each word has been converted to features) to the CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.7 s, sys: 7.99 ms, total: 4.71 s\n",
      "Wall time: 4.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CRF = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for x, y in zip(train_features, train_labels):\n",
    "    CRF.append(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the CRF with the sentences that we have add before. The resulting model will be saved with the name 'conll2003-eng.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 12s, sys: 108 ms, total: 3min 12s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CRF.train('conll2003-eng.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test phase\n",
    "\n",
    "We have used the testa data for validation purposes and the testb for the final test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.952341983418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhikia/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00         6\n",
      "      B-MISC       0.00      0.00      0.00         9\n",
      "       B-ORG       0.00      0.00      0.00         5\n",
      "       I-LOC       0.81      0.84      0.83      1919\n",
      "      I-MISC       0.72      0.68      0.70       909\n",
      "       I-ORG       0.75      0.74      0.75      2491\n",
      "       I-PER       0.84      0.89      0.86      2773\n",
      "           O       0.99      0.98      0.98     38323\n",
      "\n",
      "    accuracy                           0.95     46435\n",
      "   macro avg       0.51      0.52      0.51     46435\n",
      "weighted avg       0.95      0.95      0.95     46435\n",
      "\n",
      "confusion matrix: \n",
      "[[    0     0     0     0     0     4     2     0]\n",
      " [    0     0     0     0     5     2     2     0]\n",
      " [    0     0     0     0     0     4     1     0]\n",
      " [    0     0     0  1608    35   105    76    95]\n",
      " [    0     0     0    55   616    61    37   140]\n",
      " [    0     0     0   150    72  1851   220   198]\n",
      " [    0     0     0    63    15   139  2461    95]\n",
      " [    0     0     0    98   116   304   119 37686]]\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2003-eng.model')\n",
    "y_pred = []\n",
    "\n",
    "# use testa_features for validation and testb_features for testing\n",
    "for sentence_pred in [tagger.tag(x) for x in testb_features]:\n",
    "    for pred in sentence_pred:\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "# use testa_labels for validation and testb_labels for testing\n",
    "y_test = []\n",
    "for sentence_labels in testb_labels:\n",
    "    for label in sentence_labels:\n",
    "        y_test.append(label)\n",
    "        \n",
    "# Print results \n",
    "print('accuracy =', metrics.accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=y_pred))\n",
    "print('confusion matrix: ')\n",
    "print(metrics.confusion_matrix(y_true=y_test, y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We can see that the more data the better. In the classes where there is almost no data (B-LOC, B-MISC and B-ORG) we are not able to predict any instance, while with the classes with more data we perform much better. In the class 'O' (there is no name entity) we get more than 98 percent of precision and recall (we have to remark that a classifier that assign all claases to 'O' will get 0.82 of precision). We can see that we predict better the class I-LOC than the class I-ORG, but this last class have more that than the class I-LOC, One possible explanation to this anomaly is the lenght of each class: the names of organizations are usually longer than the locations (name of cities, for instance)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
