{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IHLT S5: Lexical semantics\n",
    "\n",
    "Jordi Armengol, Joan Llop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "from math import log\n",
    "import nltk\n",
    "# nltk.download('wordnet_ic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information content from frequencies in the Brown Corpus\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "# (lemma, category) pairs\n",
    "data = ('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'), \\\n",
    "        ('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'), \\\n",
    "        ('the', 'DT'), ('woman', 'NN'), ('walk', 'VB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the NLTK PoS tags into WordNet PoS tags\n",
    "\n",
    "We need to transform the PoS into WordNet tags since they are named differently. In case that the PoS tag is not a noun, verb, adjective or adverb, we return None, because WordNet only deals with these four categories (and in the other cases there are no synsets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_pos_to_wordnet_pos(nltk_pos):\n",
    "    mapping = {'NN': wn.NOUN, 'JJ': wn.ADJ, 'VB': wn.VERB, 'RB': wn.ADV}\n",
    "    if nltk_pos in mapping:\n",
    "        return mapping[nltk_pos]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each pair, when possible, print their most frequent WordNet synset\n",
    "The only categories that have synsets are nouns, verbs, adjectives and adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent synsets:\n",
      "\n",
      "\n",
      "('the', 'DT') doesn't have an assigned synset\n",
      "('man', 'NN') is Synset('man.n.01')\n",
      "('swim', 'VB') is Synset('swim.v.01')\n",
      "('with', 'PR') doesn't have an assigned synset\n",
      "('a', 'DT') doesn't have an assigned synset\n",
      "('girl', 'NN') is Synset('girl.n.01')\n",
      "('and', 'CC') doesn't have an assigned synset\n",
      "('a', 'DT') doesn't have an assigned synset\n",
      "('boy', 'NN') is Synset('male_child.n.01')\n",
      "('whilst', 'PR') doesn't have an assigned synset\n",
      "('the', 'DT') doesn't have an assigned synset\n",
      "('woman', 'NN') is Synset('woman.n.01')\n",
      "('walk', 'VB') is Synset('walk.v.01')\n"
     ]
    }
   ],
   "source": [
    "saved_synsets = []\n",
    "print('Most frequent synsets:\\n')\n",
    "print()\n",
    "for lemma, category in data:\n",
    "    wordnet_category = nltk_pos_to_wordnet_pos(category)\n",
    "    if wordnet_category is not None:\n",
    "        word_synsets = wn.synsets(lemma, wordnet_category)\n",
    "        if len(word_synsets) > 0:\n",
    "            most_freq_synset = word_synsets[0] # The most frequent synset is the first one\n",
    "            print(tuple((lemma, category)), 'is', most_freq_synset)\n",
    "            saved_synsets.append(most_freq_synset)\n",
    "        else:\n",
    "            # Just in case\n",
    "            print(tuple((lemma, category)), \"doesn't have an assigned synset\")\n",
    "    else:\n",
    "        # The lemma is not a noun, nor a verb, nor an adjective nor an adverb\n",
    "        print(tuple((lemma, category)), \"doesn't have an assigned synset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarities\n",
    "\n",
    "For each pair of the found synsets, we are going to print their corresponding least common subsumer (LCS) and their similarity value, using the following functions:\n",
    "\n",
    "- Path Similarity\n",
    "- Leacock-Chodorow Similarity\n",
    "- Wu-Palmer Similarity\n",
    "- Lin Similarity\n",
    "\n",
    "Notice that computing those similarities is not always possible, typically because they don't have the same PoS. In the first version we handled errors for each case, but we found out that checking whether they share the same category avoids any errors. In WordNet, it doesn't make sense to compute similarities between, say, a verb and a noun, because having different categories they don't share a common ancestor.\n",
    "\n",
    "Leacock-Chodorow Similarity have to be normalized (by dividing by the maximum possible similarity, in case the shortest path was 1, and taking into account that the maximum depth of WordNet is 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities between pairs of synsets:\n",
      "\n",
      "Skipping Synset('man.n.01') and Synset('swim.v.01') because they have different PoS\n",
      "\n",
      "Similarities between Synset('man.n.01') Synset('girl.n.01')\n",
      "LCS: Synset('adult.n.01')\n",
      "Path similarity: 0.25\n",
      "Leacock-Chodorow Similarity 0.6102915062989643\n",
      "Wu-Palmer Similarity: 0.631578947368421\n",
      "Lin similarity 0.7135111237276783\n",
      "\n",
      "Similarities between Synset('man.n.01') Synset('male_child.n.01')\n",
      "LCS: Synset('male.n.02')\n",
      "Path similarity: 0.3333333333333333\n",
      "Leacock-Chodorow Similarity 0.6882778097361639\n",
      "Wu-Palmer Similarity: 0.6666666666666666\n",
      "Lin similarity 0.7294717876200584\n",
      "\n",
      "Similarities between Synset('man.n.01') Synset('woman.n.01')\n",
      "LCS: Synset('adult.n.01')\n",
      "Path similarity: 0.3333333333333333\n",
      "Leacock-Chodorow Similarity 0.6882778097361639\n",
      "Wu-Palmer Similarity: 0.6666666666666666\n",
      "Lin similarity 0.7870841372982784\n",
      "\n",
      "Skipping Synset('man.n.01') and Synset('walk.v.01') because they have different PoS\n",
      "\n",
      "Skipping Synset('swim.v.01') and Synset('girl.n.01') because they have different PoS\n",
      "\n",
      "Skipping Synset('swim.v.01') and Synset('male_child.n.01') because they have different PoS\n",
      "\n",
      "Skipping Synset('swim.v.01') and Synset('woman.n.01') because they have different PoS\n",
      "\n",
      "Similarities between Synset('swim.v.01') Synset('walk.v.01')\n",
      "LCS: Synset('travel.v.01')\n",
      "Path similarity: 0.3333333333333333\n",
      "Leacock-Chodorow Similarity 0.585403853992859\n",
      "Wu-Palmer Similarity: 0.3333333333333333\n",
      "Lin similarity 0.4910052007916556\n",
      "\n",
      "Similarities between Synset('girl.n.01') Synset('male_child.n.01')\n",
      "LCS: Synset('person.n.01')\n",
      "Path similarity: 0.16666666666666666\n",
      "Leacock-Chodorow Similarity 0.5003759850270564\n",
      "Wu-Palmer Similarity: 0.631578947368421\n",
      "Lin similarity 0.2927280671561499\n",
      "\n",
      "Similarities between Synset('girl.n.01') Synset('woman.n.01')\n",
      "LCS: Synset('woman.n.01')\n",
      "Path similarity: 0.5\n",
      "Leacock-Chodorow Similarity 0.7981933310080719\n",
      "Wu-Palmer Similarity: 0.631578947368421\n",
      "Lin similarity 0.9067798595489287\n",
      "\n",
      "Skipping Synset('girl.n.01') and Synset('walk.v.01') because they have different PoS\n",
      "\n",
      "Similarities between Synset('male_child.n.01') Synset('woman.n.01')\n",
      "LCS: Synset('person.n.01')\n",
      "Path similarity: 0.2\n",
      "Leacock-Chodorow Similarity 0.5498006298445022\n",
      "Wu-Palmer Similarity: 0.6666666666666666\n",
      "Lin similarity 0.31842335630818425\n",
      "\n",
      "Skipping Synset('male_child.n.01') and Synset('walk.v.01') because they have different PoS\n",
      "\n",
      "Skipping Synset('woman.n.01') and Synset('walk.v.01') because they have different PoS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Similarities between pairs of synsets:')\n",
    "print()\n",
    "for index1, synset1 in enumerate(saved_synsets):\n",
    "    for index2, synset2 in enumerate(saved_synsets):\n",
    "        if index1 < index2:\n",
    "            if synset1.pos() != synset2.pos():\n",
    "                print('Skipping', synset1, 'and', synset2, 'because they have different PoS')\n",
    "                print()\n",
    "                continue\n",
    "            print('Similarities between', synset1, synset2)\n",
    "            lcs = synset1.lowest_common_hypernyms(synset2)\n",
    "            print('LCS:', lcs[0])\n",
    "            path_sim = synset1.path_similarity(synset2)\n",
    "            print('Path similarity:', path_sim)\n",
    "            leacock_chodorow_sim = synset1.lch_similarity(synset2)/-log(1/(2*20)) # Normalize by max similarity\n",
    "            print('Leacock-Chodorow Similarity', leacock_chodorow_sim)\n",
    "            wu_palmer_sim = synset1.wup_similarity(synset2)\n",
    "            print('Wu-Palmer Similarity:', wu_palmer_sim)\n",
    "            lin_sim = synset1.lin_similarity(synset2,brown_ic)\n",
    "            print('Lin similarity', lin_sim)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Conclusions: Which similarity seems better?\n",
    "\n",
    "Each metric may have its own usefulness, but as far as we are concerned, we observe that:\n",
    "- LCS, even if it's not a similarity measure, could be used as a qualitative measure of proximity.\n",
    "- Path similarity seems to give way low similarities (for instance, woman and girl always have a similarity of 0.5). It is the simplest metric, so perhaps is missing complexities.\n",
    "- Leacock-Chodorow seems to be relatively robust, but gives similar results in the different cases.\n",
    "- Wu-Palmer exhibits gives similar results in all cases, which may be true (all the examples are relatively close, semantically), but perhaps it's not that useful if what we really want to do is to fine-grained-ly compare words of the same domain, which is what we will want to do in many case.\n",
    "- Lin exhibits high variance, but at the same time it seems to give very high similarities when it needs to (woman and girl, for instance). It doesn't seem very consistent (eg. shouldn't man vs woman have the same similarity than male_child vs girl? 0.78 vs 0.29!)\n",
    "\n",
    "In our view, Leacock-Chodorow seems to be the most consistent (woman vs man and girl vs male_child gives similar results) and robust, although the results are too similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
