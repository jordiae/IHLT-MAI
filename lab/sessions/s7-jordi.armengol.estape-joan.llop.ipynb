{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IHLT-MAI S6: Word sense disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home2/users/alumnes/1202114/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     /home2/users/alumnes/1202114/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home2/users/alumnes/1202114/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr\n",
    "from nltk import pos_tag\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('conll2000')\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "nltk.download('words')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reading the trial set sentences and its respective gold standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trial/STS.input.txt') as fp:\n",
    "    data = fp.readlines()\n",
    "    \n",
    "with open('trial/STS.gs.txt') as e:\n",
    "    gs = e.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define auxiliary functions to get the disambiguated synsets from a given context (ie. sentence) and\n",
    "the part-of-speech, respectively. For getting the disambiguated synsets, we use the Lesk algorithm for\n",
    "word sense disambiguation, which requires part-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nes(sentence, binary):\n",
    "    x = pos_tag(word_tokenize(sentence))\n",
    "    nes = ne_chunk(x, binary=binary)\n",
    "    res = set([])\n",
    "    for i in nes:\n",
    "        if type(i) == nltk.tree.Tree:\n",
    "            res.add((i.label()))\n",
    "        else:\n",
    "            # pos : res.add(i[1])\n",
    "            res.add(i[0]) # word\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define two functions for the two different ways we have investigated to compute the Jaccard distance:\n",
    "- Synsets (eval_synsets): Compute the Jaccard distance between the set of the disambiguated synsets of the first\n",
    "    sentence and the set of disambiguated synsets of the second sentence.\n",
    "- Definitions (eval_definitions): Compute the Jaccard distance between the set of words in the **definitions** of the disambiguated synsets of the first sentence and the ones in the second sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation between gold and jaccard distance using NEs with binary to True: 0.5320054206469561\n",
      "Pearson correlation between gold and jaccard distance using NEs with binary to false: 0.5141109167924274\n"
     ]
    }
   ],
   "source": [
    "def jaccard_with_nes(sent1, sent2, binary):\n",
    "    nes_sent1 = get_nes(sent1, binary)\n",
    "    nes_sent2 = get_nes(sent2, binary)\n",
    "    return jaccard_distance(nes_sent1, nes_sent2)\n",
    "\n",
    "jaccard_binary = []\n",
    "jaccard_non_binary = []\n",
    "gold = []\n",
    "for index, line in enumerate(data):\n",
    "    (num, sent1, sent2) = line.split('\\t')\n",
    "    jaccard_binary.append(jaccard_with_nes(sent1, sent2, binary=True))\n",
    "    jaccard_non_binary.append(jaccard_with_nes(sent1, sent2, binary=False))\n",
    "    gold.append(int(gs[index].split('\\t')[1][0]))\n",
    "\n",
    "print('Pearson correlation between gold and jaccard distance using NEs with binary to True:', pearsonr(gold, jaccard_binary)[0])\n",
    "print('Pearson correlation between gold and jaccard distance using NEs with binary to false:', pearsonr(gold, jaccard_non_binary)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison and conclusions\n",
    "Recall that in session 2 (Document) we obtained a correlation of 0.3962389776119233 when doing the same exercise but considering words themselves and not applying any word sense disambiguation technique. This time, by applying word sense disambiguation techniques, we have slightly improved the result.\n",
    "\n",
    "However, the result obtained in this session is slightly worse than the one obtained in session 3 (Morphology), when we used lemmas instead of the original words. Lemmatization gives us the canonical form of words. Therefore, all the words derived from a root word will be considered the same. Since we are keen on measuring semantical distances, this is useful, because in word-level settings, morphological information (at least in English) introduces \"noise\".\n",
    "\n",
    "Still, using word sense disambiguation techniques should obtain better results than just using the lemmas, which is a simpler technique, at least intuitevely. The reason why we believe this is happening is that the Lesk algorithm is too simple and has a relatively low accuracy. As a future work, more complex algorithms for word sense disambiguation could be investigated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
